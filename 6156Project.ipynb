{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "NBozfoBRmLq5",
        "outputId": "bca3436c-75a1-46df-dc9f-02cf585896c7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         )\n\u001b[0;32m--> 272\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvH0JObnPv2X"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn import datasets #Import scikit-learn dataset library\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.model_selection import GridSearchCV # Import for hyperparameter tuning\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torchvision.transforms import v2\n",
        "from torchvision import tv_tensors\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45749653"
      },
      "source": [
        "#List images and subfolders and label files\n",
        "\n",
        "import os\n",
        "\n",
        "images_path = '/content/drive/MyDrive/DSBA 6156/DSBA 6156 Final Project/Data/images'\n",
        "labels_path = '/content/drive/MyDrive/DSBA 6156/DSBA 6156 Final Project/Data/labels'\n",
        "\n",
        "all_image_entries = os.listdir(images_path)\n",
        "image_subfolder_paths = [os.path.join(images_path, entry) for entry in all_image_entries if os.path.isdir(os.path.join(images_path, entry))]\n",
        "\n",
        "all_label_entries = os.listdir(labels_path)\n",
        "label_csv_paths = [os.path.join(labels_path, entry) for entry in all_label_entries if entry.endswith('.csv')]\n",
        "\n",
        "print(\"Image Subfolder Paths:\")\n",
        "print(image_subfolder_paths[:5])\n",
        "print(\"\\nLabel CSV Paths:\")\n",
        "print(label_csv_paths[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6d1289b"
      },
      "source": [
        "# Extract identifiers and remove csv extension\n",
        "\n",
        "image_identifiers = []\n",
        "for path in image_subfolder_paths:\n",
        "    identifier = os.path.basename(path)\n",
        "    image_identifiers.append(identifier)\n",
        "\n",
        "label_identifiers = []\n",
        "for path in label_csv_paths:\n",
        "    filename = os.path.basename(path)\n",
        "    identifier = os.path.splitext(filename)[0]\n",
        "    label_identifiers.append(identifier)\n",
        "\n",
        "print(\"First 5 Image Identifiers:\")\n",
        "print(image_identifiers[:5])\n",
        "print(\"\\nFirst 5 Label Identifiers:\")\n",
        "print(label_identifiers[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8e6a7c9"
      },
      "source": [
        "# Create mapping\n",
        "\n",
        "image_label_map = {}\n",
        "matched_image_identifiers = set()\n",
        "\n",
        "for label_path, label_identifier in zip(label_csv_paths, label_identifiers):\n",
        "    # Find a matching image identifier\n",
        "    matching_image_identifier = None\n",
        "    # Iterate through image identifiers to find a match.\n",
        "    for image_identifier in image_identifiers:\n",
        "        if label_identifier in image_identifier:\n",
        "            matching_image_identifier = image_identifier\n",
        "            break\n",
        "\n",
        "    if matching_image_identifier:\n",
        "        image_label_map[matching_image_identifier] = label_path\n",
        "        matched_image_identifiers.add(matching_image_identifier)\n",
        "    else:\n",
        "        print(f\"No matching image subfolder found for label identifier: {label_identifier}\")\n",
        "\n",
        "# Identify unmatched image identifiers\n",
        "all_image_identifiers_set = set(image_identifiers)\n",
        "unmatched_image_identifiers = list(all_image_identifiers_set - matched_image_identifiers)\n",
        "\n",
        "if unmatched_image_identifiers:\n",
        "    print(\"\\nUnmatched Image Identifiers (no corresponding label file):\")\n",
        "    for identifier in unmatched_image_identifiers:\n",
        "        print(identifier)\n",
        "else:\n",
        "    print(\"\\nAll image identifiers have a corresponding label file.\")\n",
        "\n",
        "# Convert to DataFrame\n",
        "df_image_labels = pd.DataFrame.from_dict(image_label_map, orient='index').reset_index()\n",
        "df_image_labels.columns = ['Image Identifier', 'Label Filename']\n",
        "\n",
        "# Add 'Label Data' column with a placeholder, will be \"None\" for now\n",
        "df_image_labels['Label Data'] = None\n",
        "\n",
        "display(df_image_labels.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72316304"
      },
      "source": [
        "#Iterate through images folers and label csv files\n",
        "\n",
        "image_label_pairs = []\n",
        "for index, row in df_image_labels.iterrows():\n",
        "    pair = {\n",
        "        'Image Identifier': row['Image Identifier'],\n",
        "        'Label Filename': row['Label Filename']\n",
        "    }\n",
        "    image_label_pairs.append(pair)\n",
        "\n",
        "print(f\"Extracted {len(image_label_pairs)} image-label pairs.\")\n",
        "if image_label_pairs:\n",
        "    print(\"First 5 extracted pairs:\")\n",
        "    for i, pair in enumerate(image_label_pairs[:5]):\n",
        "        print(f\"Pair {i+1}: {pair}\")\n",
        "else:\n",
        "    print(\"No pairs were extracted.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d123cb90"
      },
      "source": [
        "#Read label csv for each mapped pair, put into dataframe\n",
        "\n",
        "for pair in image_label_pairs:\n",
        "    try:\n",
        "        label_data_df = pd.read_csv(pair['Label Filename'])\n",
        "        pair['Label Data'] = label_data_df\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {pair['Label Filename']}: {e}\")\n",
        "        pair['Label Data'] = None # Assign None in case reading fails\n",
        "\n",
        "if image_label_pairs:\n",
        "    print(\"First 5 pairs with loaded label data:\")\n",
        "    for i, first_item in enumerate(image_label_pairs[:5]):\n",
        "        print(f\"Pair {i+1}:\")\n",
        "        print(f\"  Image Identifier: {first_item['Image Identifier']}\")\n",
        "        print(f\"  Label Filename: {first_item['Label Filename']}\")\n",
        "        print(\"  Label Data (first 5 rows):\")\n",
        "        if first_item['Label Data'] is not None:\n",
        "            display(first_item['Label Data'].head())\n",
        "        else:\n",
        "            print(\"    Failed to load data.\")\n",
        "        print(\"-\" * 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "308fbe74"
      },
      "source": [
        "#Extract image filenames and labels from label dataframe\n",
        "\n",
        "for pair in image_label_pairs:\n",
        "    if pair['Label Data'] is not None:\n",
        "        extracted_labels = []\n",
        "        for index, row in pair['Label Data'].iterrows():\n",
        "            extracted_labels.append({\n",
        "                'image_filename': row['id'],\n",
        "                'label': row['label']\n",
        "            })\n",
        "        pair['Extracted Labels'] = extracted_labels\n",
        "    else:\n",
        "        pair['Extracted Labels'] = [] # Assign empty list in case data wasn't loaded\n",
        "\n",
        "if image_label_pairs:\n",
        "    print(\"First 5 pairs with extracted labels:\")\n",
        "    for i, pair in enumerate(image_label_pairs[:5]):\n",
        "        print(f\"Pair {i+1}:\")\n",
        "        print(f\"  Image Identifier: {pair['Image Identifier']}\")\n",
        "        print(f\"  Label Filename: {pair['Label Filename']}\")\n",
        "        print(\"  Extracted Labels (first 5 entries):\")\n",
        "        if pair['Extracted Labels']:\n",
        "            for label_entry in pair['Extracted Labels'][:5]:\n",
        "                print(f\"    {label_entry}\")\n",
        "        else:\n",
        "            print(\"    No labels extracted or data was not loaded.\")\n",
        "        print(\"-\" * 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12308b5c"
      },
      "source": [
        "#Create image file paths for each image filename extracts from csv files\n",
        "\n",
        "for pair in image_label_pairs:\n",
        "    if pair['Extracted Labels']:\n",
        "        image_identifier = pair['Image Identifier']\n",
        "        for label_entry in pair['Extracted Labels']:\n",
        "            image_filename = label_entry['image_filename']\n",
        "            full_image_path = os.path.join(images_path, image_identifier, image_filename)\n",
        "            label_entry['image_path'] = full_image_path\n",
        "    else:\n",
        "        print(f\"No extracted labels for {pair['Image Identifier']}\")\n",
        "\n",
        "if image_label_pairs:\n",
        "    print(\"\\nFirst 5 pairs with constructed image paths:\")\n",
        "    for i, pair in enumerate(image_label_pairs[:5]):\n",
        "        print(f\"Pair {i+1}:\")\n",
        "        print(f\"  Image Identifier: {pair['Image Identifier']}\")\n",
        "        print(\"  Extracted Labels (first 5 entries with image_path):\")\n",
        "        if pair['Extracted Labels']:\n",
        "            for label_entry in pair['Extracted Labels'][:5]:\n",
        "                print(f\"    {label_entry}\")\n",
        "        else:\n",
        "            print(\"    No labels extracted or data was not loaded.\")\n",
        "        print(\"-\" * 20)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62226407"
      },
      "source": [
        "# Combine image path with labels extracted from csv files\n",
        "\n",
        "combined_data_list = []\n",
        "\n",
        "for pair in image_label_pairs:\n",
        "    if pair.get('Extracted Labels'):\n",
        "        for label_entry in pair['Extracted Labels']:\n",
        "            combined_data_list.append({\n",
        "                'image_path': label_entry.get('image_path'),\n",
        "                'label': label_entry.get('label')\n",
        "            })\n",
        "\n",
        "df_combined_image_labels = pd.DataFrame(combined_data_list)\n",
        "\n",
        "display(df_combined_image_labels.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbc3916e"
      },
      "source": [
        "# Summarize Labels with Counts of each to visualize how many pictures we have of each position\n",
        "\n",
        "label_counts = df_combined_image_labels['label'].value_counts().reset_index()\n",
        "label_counts.columns = ['Label', 'Count']\n",
        "\n",
        "print(\"Summary Table of Labels:\")\n",
        "display(label_counts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f69cbd00"
      },
      "source": [
        "# More visualization\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Label', y='Count', data=label_counts, palette='viridis')\n",
        "plt.title('Distribution of Image Labels')\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "923f6f90"
      },
      "source": [
        "# Filter out undefined data\n",
        "\n",
        "df_filtered_labels = df_combined_image_labels[df_combined_image_labels['label'] != 'undefined'].copy()\n",
        "\n",
        "print(\"Filtered DataFrame (first 5 rows):\")\n",
        "display(df_filtered_labels.head())\n",
        "\n",
        "print(f\"\\nNumber of rows in the filtered DataFrame: {len(df_filtered_labels)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your label as numbers\n",
        "label_mapping = {'sitting': 0, 'standing': 1, 'lying': 2}\n",
        "\n",
        "# 2. Create a custom Dataset\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Open and convert to RGB\n",
        "        img = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        # Apply transforms (resize, normalize, etc.)\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        # Convert label to tensor\n",
        "        label_num = torch.tensor(label_mapping[label], dtype=torch.long)\n",
        "\n",
        "        return img, label_num\n",
        "\n",
        "# 3. Define transforms (resize → tensor → normalize)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),   # resize\n",
        "    transforms.ToTensor(),           # convert to tensor [0,1]\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet stats\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Take a sample of the data\n",
        "sample_size = 1000\n",
        "df_sampled_labels = df_filtered_labels.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
        "\n",
        "\n",
        "# 4. Create dataset using the sampled data\n",
        "dataset = CustomImageDataset(\n",
        "    image_paths=df_sampled_labels['image_path'].tolist(),\n",
        "    labels=df_sampled_labels['label'].tolist(),\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "# 5. Create DataLoader (handles batching + parallel loading)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "# 6. Iterate through batches (optional, just for checking)\n",
        "for images, labels in dataloader:\n",
        "    print(\"Batch of images:\", images.shape)   # e.g., torch.Size([32, 3, 224, 224])\n",
        "    print(\"Batch of labels:\", labels.shape)   # e.g., torch.Size([32])\n",
        "    break"
      ],
      "metadata": {
        "id": "aczUcCd0G1br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "train_dataset, test_dataset = train_test_split(dataset, test_size=0.3, random_state=42)\n",
        "\n",
        "# Split the testing set into validation and test sets\n",
        "val_dataset, test_dataset = train_test_split(test_dataset, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Number of samples in training set: {len(train_dataset)}\")\n",
        "print(f\"Number of samples in validation set: {len(val_dataset)}\")\n",
        "print(f\"Number of samples in test set: {len(test_dataset)}\")"
      ],
      "metadata": {
        "id": "aEeSOpNNPCuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3682d28b"
      },
      "source": [
        "# Create DataLoader for the test set\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"Test DataLoader created with {len(test_dataloader)} batches.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb14a0a8"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define a simple CNN model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        # Calculate the output size of the convolutional layers\n",
        "        # Assuming input image size is 224x224 after preprocessing\n",
        "        # After conv1 and pool1: (224 / 2) x (224 / 2) = 112 x 112, 16 channels\n",
        "        # After conv2 and pool2: (112 / 2) x (112 / 2) = 56 x 56, 32 channels\n",
        "        self.fc1 = nn.Linear(32 * 56 * 56, 128)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))\n",
        "        x = self.pool2(self.relu2(self.conv2(x)))\n",
        "        x = self.flatten(x)\n",
        "        x = self.relu3(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "num_classes = len(label_mapping)  # Get the number of unique labels\n",
        "model = SimpleCNN(num_classes)\n",
        "\n",
        "print(\"Simple CNN model defined:\")\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05f876ab"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001) # Adjust learning rate as needed\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Create DataLoaders for training and validation sets\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10  # Adjust the number of epochs as needed\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_dataloader:\n",
        "        # Move data to GPU if available\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        outputs = model(images) # Forward pass\n",
        "        loss = criterion(outputs, labels) # Calculate the loss\n",
        "        loss.backward() # Backpropagate the gradients\n",
        "        optimizer.step() # Update model weights\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    # Validation (optional, but good practice)\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad(): # Disable gradient calculation for validation\n",
        "        for images, labels in val_dataloader:\n",
        "            # Move data to GPU if available\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "print(\"Training finished.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f6e4e93"
      },
      "source": [
        "# Evaluate the model on the test set\n",
        "model.eval()  # Set model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "all_predicted = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        all_predicted.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Accuracy on the test set: {accuracy:.2f}%\")\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(all_labels, all_predicted)\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=label_mapping.keys(), yticklabels=label_mapping.keys())\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}